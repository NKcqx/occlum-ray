[2023-03-01 08:35:17,556 I 353 353] core_worker_process.cc:120: Constructing CoreWorkerProcess. pid: 353
[2023-03-01 08:35:17,575 D 353 357] core_worker_process.cc:200: Getting system config from raylet, remaining retries = 10
[2023-03-01 08:35:17,575 D 353 353] ray_config.cc:70: RayConfig is initialized with: is_external_storage_type_fs=true,object_spilling_config="{\"type\": \"filesystem\", \"params\": {\"directory_path\": \"/host/tmp/ray/session_2023-03-01_08-35-02_331838_2\"}}",
[2023-03-01 08:35:17,576 D 353 353] core_worker.cc:88: Constructing CoreWorker, worker_id: 722d8a1f5b37f3b016bb2344345366e69965ba48039ff691d4fbc3df
[2023-03-01 08:35:17,576 I 353 353] core_worker.cc:119: Connecting to local Raylet.
[2023-03-01 08:35:17,576 I 353 353] raylet_client.cc:116: Creating RayletConnection.
[2023-03-01 08:35:17,576 I 353 353] client_connection.cc:47: ConnectSocketRetry begin /host/tmp/ray/session_2023-03-01_08-35-02_331838_2/sockets/raylet 0
[2023-03-01 08:35:17,577 I 353 353] client_connection.cc:51: ConnectSocketRetry end /host/tmp/ray/session_2023-03-01_08-35-02_331838_2/sockets/raylet 0. OK
[2023-03-01 08:35:17,577 I 353 353] raylet_client.cc:118: Created RayletConnection.
[2023-03-01 08:35:17,577 I 353 353] raylet_client.cc:138: Begin AtomicRequestReply RegisterClientRequest
[2023-03-01 08:35:17,578 I 353 353] raylet_client.cc:141: End AtomicRequestReply RegisterClientRequest. Status: OK
[2023-03-01 08:35:17,578 I 353 353] core_worker.cc:135: Connected to local Raylet.
[2023-03-01 08:35:17,578 I 353 353] core_worker.cc:164: Starting GRPC server.
[2023-03-01 08:35:17,578 I 353 353] grpc_server.cc:105: worker server started, listening on port 42783.
[2023-03-01 08:35:17,580 I 353 353] core_worker.cc:171: Started GRPC server.
[2023-03-01 08:35:17,580 I 353 353] core_worker.cc:179: Initializing worker at address: 172.17.0.2:42783, worker ID 722d8a1f5b37f3b016bb2344345366e69965ba48039ff691d4fbc3df, raylet 1498b5960cd2b805e30f570357aaad814936f015d40decb1eb6bdc19
[2023-03-01 08:35:17,587 I 353 368] gcs_server_address_updater.cc:32: GCS Server updater thread id: 139859113027328
[2023-03-01 08:35:17,687 D 353 353] gcs_client.cc:165: GcsClient connected.
[2023-03-01 08:35:17,687 I 353 353] core_worker.cc:205: GCS client created.
[2023-03-01 08:35:17,688 I 353 353] core_worker.cc:207: Registered to GCS.
[2023-03-01 08:35:17,688 D 353 353] subscriber.cc:348: Make a long polling request to e5c3d92d157193c3aa3334f41dadf308b38005d3cab19423ddac48f8
[2023-03-01 08:35:17,688 I 353 353] core_worker.cc:267: Creating CoreWorkerPlasmaStoreProvider
[2023-03-01 08:35:17,689 I 353 353] client.cc:762: Before ConnectSocketRetry
[2023-03-01 08:35:17,689 I 353 353] client_connection.cc:47: ConnectSocketRetry begin /host/tmp/ray/session_2023-03-01_08-35-02_331838_2/sockets/plasma_store 0
[2023-03-01 08:35:17,689 I 353 353] client_connection.cc:51: ConnectSocketRetry end /host/tmp/ray/session_2023-03-01_08-35-02_331838_2/sockets/plasma_store 0. OK
[2023-03-01 08:35:17,689 I 353 353] client.cc:764: After ConnectSocketRetry
[2023-03-01 08:35:17,689 I 353 353] client.cc:766: After new StoreConn
[2023-03-01 08:35:17,689 I 353 353] client.cc:769: After SendConnectRequest
[2023-03-01 08:35:17,690 I 353 353] client.cc:772: After PlasmaReceive
[2023-03-01 08:35:17,690 I 353 353] client.cc:774: After ReadConnectReply
[2023-03-01 08:35:17,690 D 353 353] client.cc:392: called plasma_create on conn 30 with size 8 and metadata size 0
[2023-03-01 08:35:17,690 I 353 353] protocol.cc:219: After CreatePlasmaCreateRequest, prepare to send
[2023-03-01 08:35:17,690 I 353 353] protocol.cc:221: After PlasmaSend, status: 1
[2023-03-01 08:35:17,690 I 353 353] client.cc:402: After SendCreateRequest
[2023-03-01 08:35:17,690 I 353 353] client.cc:311: Before PlasmaReceive
[2023-03-01 08:35:17,690 I 353 353] client.cc:313: After PlasmaReceive buffer size: 160
[2023-03-01 08:35:17,690 I 353 353] client.cc:327: After RreadCreateReply, retry count: 0
[2023-03-01 08:35:17,690 I 353 353] client.cc:355: After create PlasmaMutableBuffer
[2023-03-01 08:35:17,690 I 353 353] client.cc:404: After HandleCreateReply
[2023-03-01 08:35:17,690 I 353 353] core_worker.cc:277: Created CoreWorkerPlasmaStoreProvider
[2023-03-01 08:35:17,695 D 353 353] core_worker_process.cc:276: Worker 722d8a1f5b37f3b016bb2344345366e69965ba48039ff691d4fbc3df is created.
[2023-03-01 08:35:17,696 D 353 353] core_worker_process.cc:132: Stats setup in core worker.
[2023-03-01 08:35:17,696 D 353 353] stats.h:75: Initialized stats
[2023-03-01 08:35:17,696 I 353 353] io_service_pool.cc:35: IOServicePool is running with 1 io_service.
[2023-03-01 08:35:17,697 I 353 372] core_worker.cc:502: Event stats:


Global stats: 16 total (11 active)
Queueing time: mean = 2.344 ms, max = 8.650 ms, min = 5.728 ms, total = 37.501 ms
Execution time:  mean = 67.444 us, total = 1.079 ms
Event stats:
	PeriodicalRunner.RunFnPeriodically - 7 total (2 active, 1 running), CPU time: mean = 154.158 us, total = 1.079 ms
	UNKNOWN - 3 total (3 active), CPU time: mean = 0.000 s, total = 0.000 s
	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
	CoreWorker.deadline_timer.flush_profiling_events - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
	NodeManagerService.grpc_client.ReportWorkerBacklog - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
	WorkerInfoGcsService.grpc_client.AddWorkerInfo - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
	GcsClient.deadline_timer.check_gcs_connection - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s


[2023-03-01 08:35:17,697 D 353 372] accessor.cc:487: Getting information of all nodes.
[2023-03-01 08:35:17,698 D 353 353] metrics_agent_client.h:41: Initiate the metrics client of address:127.0.0.1 port:62899
[2023-03-01 08:35:17,698 I 353 372] accessor.cc:599: Received notification for node id = 1498b5960cd2b805e30f570357aaad814936f015d40decb1eb6bdc19, IsAlive = 1
[2023-03-01 08:35:17,698 D 353 372] accessor.cc:497: Finished getting information of all nodes, status = OK
[2023-03-01 08:35:17,704 D 353 366] grpc_server.cc:146: Polled event from CQ, thead: 139859104630528::0, status: 1
[2023-03-01 08:35:17,717 D 353 353] core_worker.cc:2273: Executing task, task info = Type=ACTOR_CREATION_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=demo, class_name=Owner, function_name=__init__, function_hash=2b5e28f8604b4e1b89d86570474601d8}, task_id=ffffffffffffffffc212a8a132dd01d3ed51267701000000, task_name=Owner.__init__(), job_id=01000000, num_args=0, num_returns=1, depth=1, actor_creation_task_spec={actor_id=c212a8a132dd01d3ed51267701000000, max_restarts=0, max_concurrency=1, is_asyncio_actor=0, is_detached=0}
[2023-03-01 08:35:17,717 D 353 353] reference_count.cc:242: Add local reference ffffffffffffffffc212a8a132dd01d3ed5126770100000001000000
[2023-03-01 08:35:17,717 D 353 353] reference_count.cc:243: REF ffffffffffffffffc212a8a132dd01d3ed5126770100000001000000 borrowers: 0 local_ref_count: 1 submitted_count: 0 contained_in_owned: 0 contained_in_borrowed: 0 contains: 0 stored_in: 0 lineage_ref_count: 0
[2023-03-01 08:35:17,717 I 353 353] direct_actor_task_submitter.cc:33: Set max pending calls to -1 for actor c212a8a132dd01d3ed51267701000000
[2023-03-01 08:35:17,717 D 353 353] direct_actor_task_submitter.cc:169: Connecting to actor c212a8a132dd01d3ed51267701000000 at worker 722d8a1f5b37f3b016bb2344345366e69965ba48039ff691d4fbc3df
[2023-03-01 08:35:17,718 D 353 353] core_worker_client_pool.cc:42: Connected to 172.17.0.2:42783
[2023-03-01 08:35:17,718 D 353 353] sequential_actor_submit_queue.cc:86: Resetting caller starts at for actor c212a8a132dd01d3ed51267701000000 from 0 to 0
[2023-03-01 08:35:17,718 I 353 353] direct_actor_task_submitter.cc:217: Connecting to actor c212a8a132dd01d3ed51267701000000 at worker 722d8a1f5b37f3b016bb2344345366e69965ba48039ff691d4fbc3df
[2023-03-01 08:35:17,718 D 353 353] reference_count.cc:106: Adding borrowed object ffffffffffffffffc212a8a132dd01d3ed5126770100000001000000
[2023-03-01 08:35:17,718 I 353 353] core_worker.cc:2330: Creating actor: c212a8a132dd01d3ed51267701000000
[2023-03-01 08:35:17,719 D 353 353] core_worker.cc:2407: Finished executing task ffffffffffffffffc212a8a132dd01d3ed51267701000000, status=OK
[2023-03-01 08:35:17,719 I 353 353] direct_actor_transport.cc:144: Actor creation task finished, task_id: ffffffffffffffffc212a8a132dd01d3ed51267701000000, actor_id: c212a8a132dd01d3ed51267701000000
[2023-03-01 08:35:17,720 D 353 366] grpc_server.cc:146: Polled event from CQ, thead: 139859104630528::0, status: 1
[2023-03-01 08:35:17,723 D 353 366] grpc_server.cc:146: Polled event from CQ, thead: 139859104630528::0, status: 1
[2023-03-01 08:35:17,723 D 353 353] actor_scheduling_queue.cc:89: Enqueue 0 cur seqno 0
[2023-03-01 08:35:17,723 D 353 353] core_worker.cc:2273: Executing task, task info = Type=ACTOR_TASK, Language=PYTHON, Resources: {CPU: 1, }, function_descriptor={type=PythonFunctionDescriptor, module_name=demo, class_name=Owner, function_name=warmup, function_hash=}, task_id=c54e76759b2a0c10c212a8a132dd01d3ed51267701000000, task_name=Owner.warmup(), job_id=01000000, num_args=0, num_returns=2, depth=0, actor_task_spec={actor_id=c212a8a132dd01d3ed51267701000000, actor_caller_id=ffffffffffffffffffffffffffffffffffffffff01000000, actor_counter=0}
[2023-03-01 08:35:17,724 D 353 353] reference_count.cc:183: Adding owned object 004e76759b2a0c10c212a8a132dd01d3ed5126770100000003000000
[2023-03-01 08:35:17,724 D 353 353] reference_count.cc:1164: Adding location 1498b5960cd2b805e30f570357aaad814936f015d40decb1eb6bdc19 for object 004e76759b2a0c10c212a8a132dd01d3ed5126770100000003000000
[2023-03-01 08:35:17,724 D 353 353] reference_count.cc:1367: Published message for 004e76759b2a0c10c212a8a132dd01d3ed5126770100000003000000, 1 locations, spilled url: [], spilled node ID: NIL_ID, and object size: 21, and primary node ID: 1498b5960cd2b805e30f570357aaad814936f015d40decb1eb6bdc19, pending creation? 0
[2023-03-01 08:35:17,724 D 353 353] client.cc:392: called plasma_create on conn 30 with size 16 and metadata size 5
[2023-03-01 08:35:17,724 I 353 353] protocol.cc:219: After CreatePlasmaCreateRequest, prepare to send
[2023-03-01 08:35:17,724 I 353 353] protocol.cc:221: After PlasmaSend, status: 1
[2023-03-01 08:35:17,724 I 353 353] client.cc:402: After SendCreateRequest
[2023-03-01 08:35:17,724 I 353 353] client.cc:311: Before PlasmaReceive
[2023-03-01 08:35:17,725 I 353 353] client.cc:313: After PlasmaReceive buffer size: 160
[2023-03-01 08:35:17,725 I 353 353] client.cc:327: After RreadCreateReply, retry count: 0
[2023-03-01 08:35:17,725 I 353 353] client.cc:355: After create PlasmaMutableBuffer
[2023-03-01 08:35:17,725 I 353 353] client.cc:360: Before metadata memcpy, start address: “çá1 + 16, metadata size: 5
[2023-03-01 08:35:17,725 I 353 353] client.cc:363: After metadata memcpy
[2023-03-01 08:35:17,725 I 353 353] client.cc:404: After HandleCreateReply
[2023-03-01 08:35:17,725 D 353 353] core_worker.cc:1069: Pinning sealed object 004e76759b2a0c10c212a8a132dd01d3ed5126770100000003000000
[2023-03-01 08:35:17,725 D 353 353] memory_store.cc:201: Putting object into memory store. objectid is 004e76759b2a0c10c212a8a132dd01d3ed5126770100000003000000
[2023-03-01 08:35:17,726 D 353 353] ray_object.cc:108: Before parsing metadata: 0x7f33df030230
[2023-03-01 08:35:17,726 D 353 353] ray_object.cc:112: After parsing metadata: 4
[2023-03-01 08:35:17,726 D 353 353] core_worker.cc:1111: 004e76759b2a0c10c212a8a132dd01d3ed5126770100000003000000 in plasma, doing fetch-and-get
[2023-03-01 08:35:17,726 D 353 353] core_worker.cc:1126: Plasma GET timeout -1
[2023-03-01 08:35:17,726 D 353 353] plasma_store_provider.cc:196: plasma_results[0].data: 0x7f33df039960 , data size: 16 , content: “çá1
[2023-03-01 08:35:17,726 D 353 353] plasma_store_provider.cc:206: plasma_results[0].metadata: 0x7f33df033ab0 , metadata size: 5 , content: XLANG is: 2XLANG
[2023-03-01 08:35:17,726 D 353 353] plasma_store_provider.cc:211: After parsing, data: 0x7f33de155830 and metadata: 0x7f33df033ab0
[2023-03-01 08:35:17,726 D 353 353] plasma_store_provider.cc:214: Result object: 0x7f33defe0440
[2023-03-01 08:35:17,726 D 353 353] ray_object.cc:108: Before parsing metadata: 0x7f33df033ab0
[2023-03-01 08:35:17,726 D 353 353] ray_object.cc:112: After parsing metadata: XLANG
[2023-03-01 08:35:17,726 D 353 353] ray_object.cc:108: Before parsing metadata: 0x7f33df033ab0
[2023-03-01 08:35:17,726 D 353 353] ray_object.cc:112: After parsing metadata: XLANG
[2023-03-01 08:35:17,726 D 353 353] reference_count.cc:299: Remove local reference 004e76759b2a0c10c212a8a132dd01d3ed5126770100000003000000
[2023-03-01 08:35:17,726 D 353 353] reference_count.cc:300: REF 004e76759b2a0c10c212a8a132dd01d3ed5126770100000003000000 borrowers: 0 local_ref_count: 0 submitted_count: 0 contained_in_owned: 0 contained_in_borrowed: 0 contains: 0 stored_in: 0 lineage_ref_count: 0
[2023-03-01 08:35:17,726 D 353 353] reference_count.cc:525: Attempting to delete object 004e76759b2a0c10c212a8a132dd01d3ed5126770100000003000000
[2023-03-01 08:35:17,726 D 353 353] reference_count.cc:531: REF 004e76759b2a0c10c212a8a132dd01d3ed5126770100000003000000 borrowers: 0 local_ref_count: 0 submitted_count: 0 contained_in_owned: 0 contained_in_borrowed: 0 contains: 0 stored_in: 0 lineage_ref_count: 0
[2023-03-01 08:35:17,726 D 353 366] grpc_server.cc:146: Polled event from CQ, thead: 139859104630528::0, status: 1
[2023-03-01 08:35:17,727 D 353 353] reference_count.cc:568: Deleting Reference to object 004e76759b2a0c10c212a8a132dd01d3ed5126770100000003000000
[2023-03-01 08:35:17,727 D 353 353] reference_count.cc:387: Releasing lineage for object 004e76759b2a0c10c212a8a132dd01d3ed5126770100000003000000
[2023-03-01 08:35:17,727 D 353 353] task_manager.cc:534: No lineage for object 004e76759b2a0c10c212a8a132dd01d3ed5126770100000003000000
[2023-03-01 08:35:17,727 D 353 353] ray_object.cc:108: Before parsing metadata: 0x7f33df030230
[2023-03-01 08:35:17,727 D 353 372] reference_count.cc:1153: Tried to add an object location for an object 004e76759b2a0c10c212a8a132dd01d3ed5126770100000003000000 that doesn't exist in the reference table. It can happen if the object is already evicted.
[2023-03-01 08:35:17,727 D 353 366] grpc_server.cc:146: Polled event from CQ, thead: 139859104630528::0, status: 1
[2023-03-01 08:35:17,727 D 353 353] ray_object.cc:112: After parsing metadata: 4
[2023-03-01 08:35:17,727 D 353 372] core_worker.cc:2959: Object 004e76759b2a0c10c212a8a132dd01d3ed5126770100000003000000 not found
[2023-03-01 08:35:17,727 D 353 353] core_worker.cc:2232: Creating return object c54e76759b2a0c10c212a8a132dd01d3ed5126770100000001000000
[2023-03-01 08:35:17,727 D 353 366] grpc_server.cc:146: Polled event from CQ, thead: 139859104630528::0, status: 1
[2023-03-01 08:35:17,727 D 353 372] core_worker.cc:2803: Object 004e76759b2a0c10c212a8a132dd01d3ed5126770100000003000000 is deleted. Unpinning the object.
[2023-03-01 08:35:17,727 D 353 366] grpc_server.cc:146: Polled event from CQ, thead: 139859104630528::0, status: 1
[2023-03-01 08:35:17,727 D 353 353] core_worker.cc:2424: Sealing return object c54e76759b2a0c10c212a8a132dd01d3ed5126770100000001000000
[2023-03-01 08:35:17,727 D 353 372] core_worker.cc:2831: Reference for object 004e76759b2a0c10c212a8a132dd01d3ed5126770100000003000000 has already been freed.
[2023-03-01 08:35:17,727 D 353 366] grpc_server.cc:146: Polled event from CQ, thead: 139859104630528::0, status: 1
[2023-03-01 08:35:17,727 D 353 372] core_worker.cc:2880: Got a long polling request from a node 1498b5960cd2b805e30f570357aaad814936f015d40decb1eb6bdc19
[2023-03-01 08:35:17,727 D 353 353] core_worker.cc:2407: Finished executing task c54e76759b2a0c10c212a8a132dd01d3ed51267701000000, status=OK
[2023-03-01 08:35:17,728 D 353 372] publisher.cc:322: Long polling connection initiated by 1498b5960cd2b805e30f570357aaad814936f015d40decb1eb6bdc19
[2023-03-01 08:35:17,728 D 353 366] grpc_server.cc:146: Polled event from CQ, thead: 139859104630528::0, status: 1
[2023-03-01 08:35:17,728 D 353 366] grpc_server.cc:146: Polled event from CQ, thead: 139859104630528::0, status: 1
[2023-03-01 08:35:17,728 D 353 366] grpc_server.cc:146: Polled event from CQ, thead: 139859104630528::0, status: 1
[2023-03-01 08:35:17,728 W 353 372] reference_count.cc:1415: Object locations requested for 004e76759b2a0c10c212a8a132dd01d3ed5126770100000003000000, but ref already removed. This may be a bug in the distributed reference counting protocol.
[2023-03-01 08:35:17,728 D 353 366] grpc_server.cc:146: Polled event from CQ, thead: 139859104630528::0, status: 1
[2023-03-01 08:35:17,729 D 353 366] grpc_server.cc:146: Polled event from CQ, thead: 139859104630528::0, status: 1
[2023-03-01 08:35:17,729 D 353 372] core_worker.cc:2880: Got a long polling request from a node 1498b5960cd2b805e30f570357aaad814936f015d40decb1eb6bdc19
[2023-03-01 08:35:17,729 D 353 366] grpc_server.cc:146: Polled event from CQ, thead: 139859104630528::0, status: 1
[2023-03-01 08:35:17,729 D 353 372] publisher.cc:322: Long polling connection initiated by 1498b5960cd2b805e30f570357aaad814936f015d40decb1eb6bdc19
[2023-03-01 08:35:17,729 D 353 366] grpc_server.cc:146: Polled event from CQ, thead: 139859104630528::0, status: 1
[2023-03-01 08:35:17,729 D 353 366] grpc_server.cc:146: Polled event from CQ, thead: 139859104630528::0, status: 1
[2023-03-01 08:35:17,732 D 353 366] grpc_server.cc:146: Polled event from CQ, thead: 139859104630528::0, status: 1
[2023-03-01 08:35:17,732 I 353 372] core_worker.cc:3099: Force kill actor request has received. exiting immediately...
[2023-03-01 08:35:17,732 I 353 372] core_worker.cc:599: Disconnecting to the raylet.
[2023-03-01 08:35:17,732 I 353 372] raylet_client.cc:166: RayletClient::Disconnect, exit_type=INTENDED_EXIT, has creation_task_exception_pb_bytes=0
[2023-03-01 08:35:17,732 D 353 372] logging.cc:287: Uninstall signal handlers.
