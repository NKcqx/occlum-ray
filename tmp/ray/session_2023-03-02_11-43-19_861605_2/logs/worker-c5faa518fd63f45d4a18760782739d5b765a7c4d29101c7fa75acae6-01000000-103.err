:actor_name:BackendExecutor
2023-03-02 11:43:30,583	INFO backend.py:145 -- Start to create PG.
2023-03-02 11:43:30,583	INFO backend.py:207 -- Prepare to get current PG.
2023-03-02 11:43:30,584	INFO backend.py:209 -- Current PG: None
2023-03-02 11:43:30,584	INFO placement_group.py:187 -- calling worker.core_worker.create_placement_group, name: , bundles: [{'CPU': 1, 'GPU': 0}, {'CPU': 1, 'GPU': 0}, {'CPU': 1, 'GPU': 0}], strategy: PACK, detached: False.
2023-03-02 11:43:30,585	INFO placement_group.py:191 -- created pg id: PlacementGroupID(2ed31873f4a3c9b9a477910fd47901000000), init PG class.
2023-03-02 11:43:30,585	INFO placement_group.py:193 -- created pg class, return.
2023-03-02 11:43:30,694	INFO placement_group.py:75 -- sending bundle_reservation_check.options remote task.
2023-03-02 11:43:30,697	INFO backend.py:236 -- pg_ready, wait
2023-03-02 11:43:30,697	INFO worker.py:1963 -- ray.wait
2023-03-02 11:43:32,371	INFO worker.py:2029 -- wait returned, ready_ids: [ObjectRef(e6c9c9c543058c5bffffffffffffffffffffffff0100000001000000)], remaining_ids: []
2023-03-02 11:43:32,372	INFO backend.py:149 -- Created PG: <ray.util.placement_group.PlacementGroup object at 0x7f23613a51f0>
2023-03-02 11:43:32,372	INFO backend.py:150 -- Start to create `WorkerGroup`, num_workers: 3, num_cpus_per_worker: 1, pg: <ray.util.placement_group.PlacementGroup object at 0x7f23613a51f0>, 
2023-03-02 11:43:32,372	INFO worker_group.py:158 -- Init WorkerGroup with config: num_workers: 3, num_cpus_per_worker: 1, additional_resources_per_worker: None, actor_cls: None
2023-03-02 11:43:32,372	INFO worker_group.py:170 -- Created executable class: <class 'ray.train.worker_group.BaseWorkerMixin'>
2023-03-02 11:43:32,373	INFO worker_group.py:185 -- Resources are enough, result: <ray.train.worker_group.ActorClass(BaseWorkerMixin) object at 0x7f23613a5430>
2023-03-02 11:43:35,311	INFO backend.py:166 -- WorkerGroup: <ray.train.worker_group.WorkerGroup object at 0x7f23613b2c40>
2023-03-02 11:43:35,311	INFO backend.py:182 -- _backend: <ray.train.torch.TorchBackend object at 0x7f23613a5550> calling `on_start`.
[mutex.cc : 926] RAW: pthread_getschedparam failed: 1
[mutex.cc : 926] RAW: pthread_getschedparam failed: 1
[mutex.cc : 926] RAW: pthread_getschedparam failed: 1
2023-03-02 11:43:41,533	INFO backend.py:184 -- Done calling <ray.train.torch.TorchBackend object at 0x7f23613a5550>'s `on_start`
2023-03-02 11:43:41,731	INFO worker.py:1963 -- ray.wait
2023-03-02 11:43:41,994	INFO worker.py:2029 -- wait returned, ready_ids: [ObjectRef(cfab557fec6fefe0bddded98b75382fbeb28608f0100000001000000)], remaining_ids: [ObjectRef(d87aee9e4d98d18db095930945e81767ec1f01a40100000001000000), ObjectRef(d2dd870e494366e28dd5366e97c7ef9a630bda160100000001000000)]
2023-03-02 11:43:41,995	INFO worker.py:1963 -- ray.wait
2023-03-02 11:43:41,997	INFO worker.py:2029 -- wait returned, ready_ids: [ObjectRef(d2dd870e494366e28dd5366e97c7ef9a630bda160100000001000000)], remaining_ids: [ObjectRef(d87aee9e4d98d18db095930945e81767ec1f01a40100000001000000)]
2023-03-02 11:43:41,998	INFO worker.py:1963 -- ray.wait
2023-03-02 11:43:41,998	INFO worker.py:2029 -- wait returned, ready_ids: [ObjectRef(d87aee9e4d98d18db095930945e81767ec1f01a40100000001000000)], remaining_ids: []
2023-03-02 11:43:42,008	INFO worker.py:1963 -- ray.wait
2023-03-02 11:43:42,012	INFO worker.py:2029 -- wait returned, ready_ids: [ObjectRef(a9ce36be1e7687898dd5366e97c7ef9a630bda160100000001000000)], remaining_ids: [ObjectRef(4ef5653355e7ed93b095930945e81767ec1f01a40100000001000000), ObjectRef(7bfb17883b0caa85bddded98b75382fbeb28608f0100000001000000)]
2023-03-02 11:43:42,012	INFO worker.py:1963 -- ray.wait
2023-03-02 11:43:42,013	INFO worker.py:2029 -- wait returned, ready_ids: [ObjectRef(7bfb17883b0caa85bddded98b75382fbeb28608f0100000001000000)], remaining_ids: [ObjectRef(4ef5653355e7ed93b095930945e81767ec1f01a40100000001000000)]
2023-03-02 11:43:42,013	INFO worker.py:1963 -- ray.wait
2023-03-02 11:43:42,013	INFO worker.py:2029 -- wait returned, ready_ids: [ObjectRef(4ef5653355e7ed93b095930945e81767ec1f01a40100000001000000)], remaining_ids: []
2023-03-02 11:43:42,020	INFO worker.py:1963 -- ray.wait
2023-03-02 11:43:42,020	INFO worker.py:2029 -- wait returned, ready_ids: [ObjectRef(917d9d77803a9af0b095930945e81767ec1f01a40100000001000000)], remaining_ids: [ObjectRef(89487d6c15fd49b3bddded98b75382fbeb28608f0100000001000000), ObjectRef(ca48a9f451b787798dd5366e97c7ef9a630bda160100000001000000)]
2023-03-02 11:43:42,021	INFO worker.py:1963 -- ray.wait
2023-03-02 11:43:42,021	INFO worker.py:2029 -- wait returned, ready_ids: [ObjectRef(89487d6c15fd49b3bddded98b75382fbeb28608f0100000001000000)], remaining_ids: [ObjectRef(ca48a9f451b787798dd5366e97c7ef9a630bda160100000001000000)]
2023-03-02 11:43:42,022	INFO worker.py:1963 -- ray.wait
2023-03-02 11:43:42,022	INFO worker.py:2029 -- wait returned, ready_ids: [ObjectRef(ca48a9f451b787798dd5366e97c7ef9a630bda160100000001000000)], remaining_ids: []
2023-03-02 11:43:42,028	INFO worker.py:1963 -- ray.wait
2023-03-02 11:43:42,029	INFO worker.py:2029 -- wait returned, ready_ids: [ObjectRef(444f4cb785a6a8f2b095930945e81767ec1f01a40100000001000000)], remaining_ids: [ObjectRef(47b303f238dd015bbddded98b75382fbeb28608f0100000001000000), ObjectRef(013a82e82f2bdd858dd5366e97c7ef9a630bda160100000001000000)]
2023-03-02 11:43:42,029	INFO worker.py:1963 -- ray.wait
2023-03-02 11:43:42,030	INFO worker.py:2029 -- wait returned, ready_ids: [ObjectRef(47b303f238dd015bbddded98b75382fbeb28608f0100000001000000)], remaining_ids: [ObjectRef(013a82e82f2bdd858dd5366e97c7ef9a630bda160100000001000000)]
2023-03-02 11:43:42,030	INFO worker.py:1963 -- ray.wait
2023-03-02 11:43:42,031	INFO worker.py:2029 -- wait returned, ready_ids: [ObjectRef(013a82e82f2bdd858dd5366e97c7ef9a630bda160100000001000000)], remaining_ids: []
2023-03-02 11:43:42,036	INFO worker.py:1963 -- ray.wait
2023-03-02 11:43:42,040	INFO worker.py:2029 -- wait returned, ready_ids: [ObjectRef(e3118c6dca86f1ed8dd5366e97c7ef9a630bda160100000001000000)], remaining_ids: [ObjectRef(02c39ce33c63558fb095930945e81767ec1f01a40100000001000000), ObjectRef(c249f2ba9ed5445dbddded98b75382fbeb28608f0100000001000000)]
2023-03-02 11:43:42,045	ERROR worker.py:94 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::BaseWorkerMixin._BaseWorkerMixin__execute()[39m (pid=189, ip=172.17.0.2, repr=<ray.train.worker_group.BaseWorkerMixin object at 0x7f255d234f70>)
  File "/lib/python3.8/site-packages/ray/train/worker_group.py", line 26, in __execute
    return func(*args, **kwargs)
  File "/lib/python3.8/site-packages/ray/train/backend.py", line 506, in end_training
    output = session.finish()
  File "/lib/python3.8/site-packages/ray/train/session.py", line 118, in finish
    func_output = self.training_thread.join()
  File "/lib/python3.8/site-packages/ray/train/utils.py", line 96, in join
    raise self.exc
  File "/lib/python3.8/site-packages/ray/train/utils.py", line 89, in run
    self.ret = self._target(*self._args, **self._kwargs)
  File "/lib/python3.8/site-packages/ray/train/utils.py", line 138, in <lambda>
    return lambda: train_func(config)
  File "/root/pytorch_ray.py", line 108, in train_func
    train_loader = _prepare_train_data()
  File "/root/pytorch_ray.py", line 66, in _prepare_train_data
    train_data = datasets.MNIST(root = "/root/data", # data path in Occlum, instead of the host
  File "/lib/python3.8/site-packages/torchvision/datasets/mnist.py", line 102, in __init__
    raise RuntimeError("Dataset not found. You can use download=True to download it")
RuntimeError: Dataset not found. You can use download=True to download it
2023-03-02 11:43:42,045	ERROR worker.py:94 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::BaseWorkerMixin._BaseWorkerMixin__execute()[39m (pid=188, ip=172.17.0.2, repr=<ray.train.worker_group.BaseWorkerMixin object at 0x7f252723ef70>)
  File "/lib/python3.8/site-packages/ray/train/worker_group.py", line 26, in __execute
    return func(*args, **kwargs)
  File "/lib/python3.8/site-packages/ray/train/backend.py", line 506, in end_training
    output = session.finish()
  File "/lib/python3.8/site-packages/ray/train/session.py", line 118, in finish
    func_output = self.training_thread.join()
  File "/lib/python3.8/site-packages/ray/train/utils.py", line 96, in join
    raise self.exc
  File "/lib/python3.8/site-packages/ray/train/utils.py", line 89, in run
    self.ret = self._target(*self._args, **self._kwargs)
  File "/lib/python3.8/site-packages/ray/train/utils.py", line 138, in <lambda>
    return lambda: train_func(config)
  File "/root/pytorch_ray.py", line 108, in train_func
    train_loader = _prepare_train_data()
  File "/root/pytorch_ray.py", line 66, in _prepare_train_data
    train_data = datasets.MNIST(root = "/root/data", # data path in Occlum, instead of the host
  File "/lib/python3.8/site-packages/torchvision/datasets/mnist.py", line 102, in __init__
    raise RuntimeError("Dataset not found. You can use download=True to download it")
RuntimeError: Dataset not found. You can use download=True to download it
